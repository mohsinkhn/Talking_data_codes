{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from data_frame import DataFrame\n",
    "from tf_utils import lstm_layer, time_distributed_dense_layer, sequence_log_loss\n",
    "from tf_base_model import TFBaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ip_attributed_history    (277396, 1000)\n",
      "ip_history_length             (277396,)\n",
      "ip_id                         (277396,)\n",
      "ip_next_download              (277396,)\n",
      "ip_time_delta_history    (277396, 1000)\n",
      "dtype: object\n",
      "loaded data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "\n",
      "new run with parameters:\n",
      "{'batch_size': 128,\n",
      " 'checkpoint_dir': './checkpoints',\n",
      " 'early_stopping_steps': 20000,\n",
      " 'enable_parameter_averaging': False,\n",
      " 'grad_clip': 5,\n",
      " 'keep_prob_scalar': 1.0,\n",
      " 'learning_rate': 0.001,\n",
      " 'log_dir': './logs',\n",
      " 'log_interval': 20,\n",
      " 'loss_averaging_window': 100,\n",
      " 'lstm_size': 300,\n",
      " 'min_steps_to_checkpoint': 2500,\n",
      " 'num_restarts': 0,\n",
      " 'num_training_steps': 200000,\n",
      " 'num_validation_batches': 4,\n",
      " 'optimizer': 'adam',\n",
      " 'prediction_dir': './predictions',\n",
      " 'reader': <__main__.DataReader object at 0x7f40481f6898>,\n",
      " 'regularization_constant': 0.0,\n",
      " 'warm_start_init_step': 0}\n",
      "\n",
      "new run with parameters:\n",
      "{'batch_size': 128,\n",
      " 'checkpoint_dir': './checkpoints',\n",
      " 'early_stopping_steps': 20000,\n",
      " 'enable_parameter_averaging': False,\n",
      " 'grad_clip': 5,\n",
      " 'keep_prob_scalar': 1.0,\n",
      " 'learning_rate': 0.001,\n",
      " 'log_dir': './logs',\n",
      " 'log_interval': 20,\n",
      " 'loss_averaging_window': 100,\n",
      " 'lstm_size': 300,\n",
      " 'min_steps_to_checkpoint': 2500,\n",
      " 'num_restarts': 0,\n",
      " 'num_training_steps': 200000,\n",
      " 'num_validation_batches': 4,\n",
      " 'optimizer': 'adam',\n",
      " 'prediction_dir': './predictions',\n",
      " 'reader': <__main__.DataReader object at 0x7f40481f6898>,\n",
      " 'regularization_constant': 0.0,\n",
      " 'warm_start_init_step': 0}\n",
      "\n",
      "new run with parameters:\n",
      "{'batch_size': 128,\n",
      " 'checkpoint_dir': './checkpoints',\n",
      " 'early_stopping_steps': 20000,\n",
      " 'enable_parameter_averaging': False,\n",
      " 'grad_clip': 5,\n",
      " 'keep_prob_scalar': 1.0,\n",
      " 'learning_rate': 0.001,\n",
      " 'log_dir': './logs',\n",
      " 'log_interval': 20,\n",
      " 'loss_averaging_window': 100,\n",
      " 'lstm_size': 300,\n",
      " 'min_steps_to_checkpoint': 2500,\n",
      " 'num_restarts': 0,\n",
      " 'num_training_steps': 200000,\n",
      " 'num_validation_batches': 4,\n",
      " 'optimizer': 'adam',\n",
      " 'prediction_dir': './predictions',\n",
      " 'reader': <__main__.DataReader object at 0x7f40481f6898>,\n",
      " 'regularization_constant': 0.0,\n",
      " 'warm_start_init_step': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 249656\n",
      "val size 27740\n",
      "test size 277396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "all parameters:\n",
      "all parameters:\n",
      "all parameters:\n",
      "[('ip_embeddings:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias:0', [1200]),\n",
      " ('dense1/weights:0', [902, 50]),\n",
      " ('dense1/biases:0', [50]),\n",
      " ('dense2/weights:0', [50, 1]),\n",
      " ('dense2/biases:0', [1]),\n",
      " ('Variable:0', []),\n",
      " ('Variable_1:0', []),\n",
      " ('beta1_power:0', []),\n",
      " ('beta2_power:0', []),\n",
      " ('ip_embeddings/Adam:0', [277397, 300]),\n",
      " ('ip_embeddings/Adam_1:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel/Adam:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/kernel/Adam_1:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias/Adam:0', [1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias/Adam_1:0', [1200]),\n",
      " ('dense1/weights/Adam:0', [902, 50]),\n",
      " ('dense1/weights/Adam_1:0', [902, 50]),\n",
      " ('dense1/biases/Adam:0', [50]),\n",
      " ('dense1/biases/Adam_1:0', [50]),\n",
      " ('dense2/weights/Adam:0', [50, 1]),\n",
      " ('dense2/weights/Adam_1:0', [50, 1]),\n",
      " ('dense2/biases/Adam:0', [1]),\n",
      " ('dense2/biases/Adam_1:0', [1])]\n",
      "[('ip_embeddings:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias:0', [1200]),\n",
      " ('dense1/weights:0', [902, 50]),\n",
      " ('dense1/biases:0', [50]),\n",
      " ('dense2/weights:0', [50, 1]),\n",
      " ('dense2/biases:0', [1]),\n",
      " ('Variable:0', []),\n",
      " ('Variable_1:0', []),\n",
      " ('beta1_power:0', []),\n",
      " ('beta2_power:0', []),\n",
      " ('ip_embeddings/Adam:0', [277397, 300]),\n",
      " ('ip_embeddings/Adam_1:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel/Adam:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/kernel/Adam_1:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias/Adam:0', [1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias/Adam_1:0', [1200]),\n",
      " ('dense1/weights/Adam:0', [902, 50]),\n",
      " ('dense1/weights/Adam_1:0', [902, 50]),\n",
      " ('dense1/biases/Adam:0', [50]),\n",
      " ('dense1/biases/Adam_1:0', [50]),\n",
      " ('dense2/weights/Adam:0', [50, 1]),\n",
      " ('dense2/weights/Adam_1:0', [50, 1]),\n",
      " ('dense2/biases/Adam:0', [1]),\n",
      " ('dense2/biases/Adam_1:0', [1])]\n",
      "[('ip_embeddings:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias:0', [1200]),\n",
      " ('dense1/weights:0', [902, 50]),\n",
      " ('dense1/biases:0', [50]),\n",
      " ('dense2/weights:0', [50, 1]),\n",
      " ('dense2/biases:0', [1]),\n",
      " ('Variable:0', []),\n",
      " ('Variable_1:0', []),\n",
      " ('beta1_power:0', []),\n",
      " ('beta2_power:0', []),\n",
      " ('ip_embeddings/Adam:0', [277397, 300]),\n",
      " ('ip_embeddings/Adam_1:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel/Adam:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/kernel/Adam_1:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias/Adam:0', [1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias/Adam_1:0', [1200]),\n",
      " ('dense1/weights/Adam:0', [902, 50]),\n",
      " ('dense1/weights/Adam_1:0', [902, 50]),\n",
      " ('dense1/biases/Adam:0', [50]),\n",
      " ('dense1/biases/Adam_1:0', [50]),\n",
      " ('dense2/weights/Adam:0', [50, 1]),\n",
      " ('dense2/weights/Adam_1:0', [50, 1]),\n",
      " ('dense2/biases/Adam:0', [1]),\n",
      " ('dense2/biases/Adam_1:0', [1])]\n",
      "trainable parameters:\n",
      "trainable parameters:\n",
      "trainable parameters:\n",
      "[('ip_embeddings:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias:0', [1200]),\n",
      " ('dense1/weights:0', [902, 50]),\n",
      " ('dense1/biases:0', [50]),\n",
      " ('dense2/weights:0', [50, 1]),\n",
      " ('dense2/biases:0', [1])]\n",
      "[('ip_embeddings:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias:0', [1200]),\n",
      " ('dense1/weights:0', [902, 50]),\n",
      " ('dense1/biases:0', [50]),\n",
      " ('dense2/weights:0', [50, 1]),\n",
      " ('dense2/biases:0', [1])]\n",
      "[('ip_embeddings:0', [277397, 300]),\n",
      " ('lstm1/rnn/lstm_cell/kernel:0', [902, 1200]),\n",
      " ('lstm1/rnn/lstm_cell/bias:0', [1200]),\n",
      " ('dense1/weights:0', [902, 50]),\n",
      " ('dense1/biases:0', [50]),\n",
      " ('dense2/weights:0', [50, 1]),\n",
      " ('dense2/biases:0', [1])]\n",
      "trainable parameter count:\n",
      "trainable parameter count:\n",
      "trainable parameter count:\n",
      "84347901\n",
      "84347901\n",
      "84347901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "built graph\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [512] vs. [512,1000]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast, Log)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_294_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'mul', defined at:\n  File \"/home/mohsin/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mohsin/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-ff18af85f525>\", line 171, in <module>\n    num_validation_batches=4,\n  File \"<ipython-input-5-ff18af85f525>\", line 87, in __init__\n    super(rnn, self).__init__(**kwargs)\n  File \"/home/mohsin/Kaggle_competitions/Talking_data/Talking_data_codes/tf_base_model.py\", line 97, in __init__\n    self.graph = self.build_graph()\n  File \"/home/mohsin/Kaggle_competitions/Talking_data/Talking_data_codes/tf_base_model.py\", line 335, in build_graph\n    self.loss = self.calculate_loss()\n  File \"<ipython-input-5-ff18af85f525>\", line 92, in calculate_loss\n    loss = sequence_log_loss(self.ip_next_download, preds, self.ip_history_length, 1)\n  File \"/home/mohsin/Kaggle_competitions/Talking_data/Talking_data_codes/tf_utils.py\", line 202, in sequence_log_loss\n    log_losses = y*tf.log(y_hat) + (1.0 - y)*tf.log(1.0 - y_hat)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [512] vs. [512,1000]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast, Log)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_294_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [512] vs. [512,1000]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast, Log)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_294_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ff18af85f525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mnum_validation_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Kaggle_competitions/Talking_data/Talking_data_codes/tf_base_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 [val_loss] = self.session.run(\n\u001b[1;32m    139\u001b[0m                     \u001b[0mfetches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_feed_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 )\n\u001b[1;32m    142\u001b[0m                 \u001b[0mval_loss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [512] vs. [512,1000]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast, Log)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_294_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'mul', defined at:\n  File \"/home/mohsin/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mohsin/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-ff18af85f525>\", line 171, in <module>\n    num_validation_batches=4,\n  File \"<ipython-input-5-ff18af85f525>\", line 87, in __init__\n    super(rnn, self).__init__(**kwargs)\n  File \"/home/mohsin/Kaggle_competitions/Talking_data/Talking_data_codes/tf_base_model.py\", line 97, in __init__\n    self.graph = self.build_graph()\n  File \"/home/mohsin/Kaggle_competitions/Talking_data/Talking_data_codes/tf_base_model.py\", line 335, in build_graph\n    self.loss = self.calculate_loss()\n  File \"<ipython-input-5-ff18af85f525>\", line 92, in calculate_loss\n    loss = sequence_log_loss(self.ip_next_download, preds, self.ip_history_length, 1)\n  File \"/home/mohsin/Kaggle_competitions/Talking_data/Talking_data_codes/tf_utils.py\", line 202, in sequence_log_loss\n    log_losses = y*tf.log(y_hat) + (1.0 - y)*tf.log(1.0 - y_hat)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mohsin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [512] vs. [512,1000]\n\t [[Node: mul = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Cast, Log)]]\n\t [[Node: truediv/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_294_truediv\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "class DataReader(object):\n",
    "\n",
    "    def __init__(self, data_dir):\n",
    "#         data_cols = [\n",
    "#             'ip_id',\n",
    "#             'app_id',\n",
    "#             'channel_id',\n",
    "#             'os_id',\n",
    "#             'device_id',\n",
    "#             'ip_attributed_history',\n",
    "#             'app_attributed_history',\n",
    "#             'channel_attributed_history',\n",
    "#             'os_attributed_history',\n",
    "#             'device_attributed_history',\n",
    "#             'ip_time_delta_history',\n",
    "#             'app_time_delta_history',\n",
    "#             'channel_time_delta_history',\n",
    "#             'os_time_delta_history',\n",
    "#             'device_time_delta_history',\n",
    "#             'ip_history_length',\n",
    "#             'app_history_length',\n",
    "#             'channel_history_length',\n",
    "#             'os_history_length',\n",
    "#             'device_history_length',\n",
    "#         ]\n",
    "        data_cols = [\n",
    "                'ip_id',\n",
    "                'ip_attributed_history',\n",
    "                'ip_time_delta_history',\n",
    "                'ip_history_length',\n",
    "                'ip_next_download'\n",
    "            ]\n",
    "        data = [np.load(os.path.join(data_dir, '{}.npy'.format(i)), mmap_mode='r') for i in data_cols]\n",
    "        self.test_df = DataFrame(columns=data_cols, data=data)\n",
    "\n",
    "        print(self.test_df.shapes())\n",
    "        print('loaded data')\n",
    "\n",
    "        self.train_df, self.val_df = self.test_df.train_test_split(train_size=0.9)\n",
    "\n",
    "        print('train size', len(self.train_df))\n",
    "        print('val size', len(self.val_df))\n",
    "        print('test size', len(self.test_df))\n",
    "\n",
    "    def train_batch_generator(self, batch_size):\n",
    "        return self.batch_generator(\n",
    "            batch_size=batch_size,\n",
    "            df=self.train_df,\n",
    "            shuffle=True,\n",
    "            num_epochs=10000,\n",
    "            is_test=False\n",
    "        )\n",
    "\n",
    "    def val_batch_generator(self, batch_size):\n",
    "        return self.batch_generator(\n",
    "            batch_size=batch_size,\n",
    "            df=self.val_df,\n",
    "            shuffle=True,\n",
    "            num_epochs=10000,\n",
    "            is_test=False\n",
    "        )\n",
    "\n",
    "    def test_batch_generator(self, batch_size):\n",
    "        return self.batch_generator(\n",
    "            batch_size=batch_size,\n",
    "            df=self.test_df,\n",
    "            shuffle=False,\n",
    "            num_epochs=1,\n",
    "            is_test=True\n",
    "        )\n",
    "\n",
    "    def batch_generator(self, batch_size, df, shuffle=True, num_epochs=10000, is_test=False):\n",
    "        batch_gen = df.batch_generator(batch_size, shuffle=shuffle, num_epochs=num_epochs, allow_smaller_final_batch=is_test)\n",
    "        for batch in batch_gen:\n",
    "            batch['ip_attributed_history'] = np.roll(batch['ip_attributed_history'], -1, axis=1)\n",
    "            batch['ip_time_delta_history'] = np.roll(batch['ip_time_delta_history'], -1, axis=1)\n",
    "            batch['ip_next_download'] = batch['ip_next_download'] - 1\n",
    "            if not is_test:\n",
    "                batch['ip_history_length'] = batch['ip_history_length'] - 1\n",
    "            yield batch\n",
    "\n",
    "\n",
    "class rnn(TFBaseModel):\n",
    "\n",
    "    def __init__(self, lstm_size=300, **kwargs):\n",
    "        self.lstm_size = lstm_size\n",
    "        super(rnn, self).__init__(**kwargs)\n",
    "\n",
    "    def calculate_loss(self):\n",
    "        x = self.get_input_sequences()\n",
    "        preds = self.calculate_outputs(x)\n",
    "        loss = sequence_log_loss(self.ip_next_download, preds, self.ip_history_length, 1000)\n",
    "        return loss\n",
    "\n",
    "    def get_input_sequences(self):\n",
    "        self.ip_id = tf.placeholder(tf.int32, [None])\n",
    "        self.ip_history_length = tf.placeholder(tf.int32, [None])\n",
    "        self.ip_next_download = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "        self.ip_attributed_history = tf.placeholder(tf.int32, [None, 1000])\n",
    "        self.ip_time_delta_history = tf.placeholder(tf.int32, [None, 1000])\n",
    "\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        self.is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        # ip data\n",
    "        ip_embeddings = tf.get_variable(\n",
    "            name='ip_embeddings',\n",
    "            shape=[277397, self.lstm_size],\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        x_ip = tf.nn.embedding_lookup(ip_embeddings, self.ip_id)\n",
    "        x_ip = tf.tile(tf.expand_dims(x_ip, 1), (1, 1000, 1))\n",
    "\n",
    "        # sequence data\n",
    "        ip_attributed_history = tf.one_hot(self.ip_attributed_history, 2)\n",
    "        ip_time_delta_history = tf.one_hot(self.ip_time_delta_history, 300)\n",
    "\n",
    "        x_history = tf.concat([\n",
    "            ip_attributed_history,\n",
    "            ip_time_delta_history,\n",
    "        ], axis=2)\n",
    "\n",
    "        x = tf.concat([x_history, x_ip], axis=2)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def calculate_outputs(self, x):\n",
    "        h = lstm_layer(x, self.ip_history_length, self.lstm_size, scope='lstm1')\n",
    "        h = tf.concat([h, x], axis=2)\n",
    "\n",
    "        self.h_final = time_distributed_dense_layer(h, 50, activation=tf.nn.relu, scope='dense1')\n",
    "        y_hat = tf.squeeze(time_distributed_dense_layer(self.h_final, 1, activation=tf.nn.sigmoid, scope='dense2'), 2)\n",
    "\n",
    "        final_temporal_idx = tf.stack([tf.range(tf.shape(self.ip_history_length)[0]), self.ip_history_length - 1], axis=1)\n",
    "        self.final_states = tf.gather_nd(self.h_final, final_temporal_idx)\n",
    "        self.final_predictions = tf.gather_nd(y_hat, final_temporal_idx)\n",
    "\n",
    "        self.prediction_tensors = {\n",
    "            'ip_ids': self.ip_id,\n",
    "            'final_states': self.final_states,\n",
    "            'predictions': self.final_predictions\n",
    "        }\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base_dir = './'\n",
    "\n",
    "    dr = DataReader(data_dir=os.path.join(base_dir, '..','input', 'processed'))\n",
    "\n",
    "    nn = rnn(\n",
    "        reader=dr,\n",
    "        log_dir=os.path.join(base_dir, 'logs'),\n",
    "        checkpoint_dir=os.path.join(base_dir, 'checkpoints'),\n",
    "        prediction_dir=os.path.join(base_dir, 'predictions'),\n",
    "        optimizer='adam',\n",
    "        learning_rate=.001,\n",
    "        lstm_size=300,\n",
    "        batch_size=128,\n",
    "        num_training_steps=200000,\n",
    "        early_stopping_steps=20000,\n",
    "        warm_start_init_step=0,\n",
    "        regularization_constant=0.0,\n",
    "        keep_prob=1.0,\n",
    "        enable_parameter_averaging=False,\n",
    "        num_restarts=0,\n",
    "        min_steps_to_checkpoint=2500,\n",
    "        log_interval=20,\n",
    "        num_validation_batches=4,\n",
    "    )\n",
    "    nn.fit()\n",
    "    nn.restore()\n",
    "    nn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
